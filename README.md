üìö BookWriter AI - Asistente de Escritura Local con Memoria a Largo Plazo

BookWriter AI es una aplicaci√≥n de escritorio construida con Python y Gradio que te permite escribir novelas y libros largos con la ayuda de modelos de lenguaje de √∫ltima generaci√≥n a trav√©s de la API de Groq.

Su caracter√≠stica principal es un sistema de memoria dual:

    Memoria a Corto Plazo: Recuerda lo √∫ltimo que se escribi√≥ para una continuidad fluida.

    Memoria a Largo Plazo (Sem√°ntica): Utiliza embeddings vectoriales y una base de datos local (FAISS) gestionada por Ollama para recordar detalles clave de toda la novela, garantizando una consistencia profunda en tramas complejas y arcos de personajes largos.

Caracter√≠sticas

    Interfaz Gr√°fica Sencilla: Gestiona tus proyectos, genera contenido y visualiza tu libro, todo desde una interfaz web local.

    Generaci√≥n de Outlines: Proporciona una premisa y la IA dise√±ar√° la estructura completa de tu libro, incluyendo el mundo, los personajes y un resumen de cada cap√≠tulo.

    Escritura Asistida por IA: Genera el libro p√°gina por p√°gina, manteniendo siempre el contexto y la coherencia.

    Memoria Sem√°ntica Local: Gracias a Ollama, el sistema comprende el contenido de los cap√≠tulos ya escritos y utiliza esa informaci√≥n para guiar la escritura de los nuevos, evitando contradicciones.

    Configuraci√≥n Flexible: Controla qu√© modelo de Groq usar y ajusta sus par√°metros (temperatura, top_p, etc.) directamente desde un archivo .env.

    Exportaci√≥n a PDF: Convierte tu manuscrito en un PDF listo para compartir.

    Privacidad: Todo tu trabajo y la memoria sem√°ntica se guardan localmente en tu computadora.

üõ†Ô∏è Instalaci√≥n y Configuraci√≥n

Sigue estos pasos para poner en marcha el proyecto en tu m√°quina local.
Paso 1: Requisitos Previos (Instalar Ollama)

La memoria a largo plazo de esta aplicaci√≥n depende de Ollama. Debes instalarlo primero.

    Descarga Ollama: Ve a ollama.com y descarga la aplicaci√≥n para tu sistema operativo (macOS, Linux, Windows).

    Inicia Ollama: Una vez instalado, aseg√∫rate de que la aplicaci√≥n de Ollama est√© en ejecuci√≥n. Deber√≠as ver un √≠cono en tu barra de tareas o men√∫.

    Descarga el Modelo de Embeddings: Abre una terminal o l√≠nea de comandos y ejecuta el siguiente comando. Este modelo es el "cerebro" que permitir√° a la aplicaci√≥n entender el significado de tu libro.

    ollama pull snowflake-arctic-embed:335m

    La descarga tardar√° unos minutos. Una vez completada, puedes dejar Ollama corriendo en segundo plano.

Paso 2: Clonar el Repositorio

git clone [https://github.com/tu_usuario/BookWriter_Groq_Local.git](https://github.com/tu_usuario/BookWriter_Groq_Local.git)
cd BookWriter_Groq_Local

Paso 3: Crear un Entorno Virtual y Instalar Dependencias

Es una buena pr√°ctica usar un entorno virtual para aislar las dependencias del proyecto.

# Crear un entorno virtual
python3 -m venv env

# Activar el entorno virtual
# En macOS / Linux:
source env/bin/activate
# En Windows:
.\env\Scripts\activate

# Instalar las librer√≠as necesarias
pip install -r requirements.txt

Paso 4: Configurar tus Variables de Entorno

    Crea tu API Key de Groq: Ve a console.groq.com/keys y crea una nueva clave de API.

    Configura el archivo .env:

        Renombra el archivo .env.example a .env.

        Abre el archivo .env y pega tu clave de API de Groq donde se indica.

        Puedes ajustar opcionalmente los otros par√°metros del modelo si lo deseas.

‚ñ∂Ô∏è Ejecuci√≥n de la Aplicaci√≥n

Con Ollama corriendo en segundo plano y tu entorno virtual activado, inicia la aplicaci√≥n con el siguiente comando:

python app.py

Abre tu navegador web y ve a la direcci√≥n URL que aparece en la terminal (normalmente http://127.0.0.1:7860).

¬°Y listo! Ya puedes empezar a crear tu pr√≥xima gran novela.