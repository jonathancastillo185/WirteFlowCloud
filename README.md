üìö BookWriter AI - Asistente de Escritura Local

BookWriter AI es una aplicaci√≥n de escritorio que utiliza el poder de los grandes modelos de lenguaje (LLMs) para ayudarte a escribir novelas completas, manteniendo una coherencia profunda en la trama y los personajes de principio a fin.

El sistema combina la velocidad de la API de Groq para la generaci√≥n de texto, una memoria sem√°ntica local con Ollama y FAISS para la coherencia a largo plazo, y la API de Stability AI para generar portadas √∫nicas para tus libros.
‚ú® Caracter√≠sticas

    Generaci√≥n de Outlines Detallados: Proporciona una premisa y la IA crear√° una estructura completa para tu libro, incluyendo el mundo, los personajes y un resumen de cada cap√≠tulo.

    Memoria a Largo Plazo: Utiliza embeddings vectoriales para "recordar" detalles de cap√≠tulos anteriores, asegurando que los personajes y la trama se mantengan consistentes.

    Escritura Asistida: Genera el libro p√°gina por p√°gina o ponlo en "piloto autom√°tico" para que escriba todo el libro por ti.

    Creaci√≥n de Res√∫menes: Genera autom√°ticamente un resumen de contraportada (blurb) atractivo y comercial.

    Generaci√≥n de Portadas con IA: Crea una portada √∫nica y art√≠stica para tu libro basada en su contenido.

    Exportaci√≥n Profesional: Exporta tu manuscrito a un PDF con formato de e-book, incluyendo portada, √≠ndice de contenidos interactivo y resumen.

    Totalmente Local y Privado: La memoria sem√°ntica y la generaci√≥n de embeddings se ejecutan en tu propia m√°quina gracias a Ollama, garantizando tu privacidad.

üõ†Ô∏è Instalaci√≥n

Sigue estos pasos para poner en marcha el proyecto en tu m√°quina local.
Prerrequisitos

Necesitas tener Python 3.10 o superior y Git instalados en tu sistema.
1. Clonar el Repositorio

Abre una terminal y clona este repositorio:

git clone <URL_DEL_REPOSITORIO>
cd BookWriter_Groq_Local

2. Crear un Entorno Virtual

Es altamente recomendable usar un entorno virtual para aislar las dependencias del proyecto.

python -m venv env
source env/bin/activate  # En Windows: env\Scripts\activate

3. Instalar Dependencias de Python

Instala todas las librer√≠as necesarias con un solo comando:

pip install -r requirements.txt

4. Configurar Ollama (Para la Memoria a Largo Plazo)

Ollama es el motor que nos permite ejecutar modelos de embeddings localmente. Es crucial para la coherencia del libro.

    Descarga e Instala Ollama: Ve a ollama.com y descarga la aplicaci√≥n para tu sistema operativo (macOS, Linux, Windows).

    Ejecuta Ollama: Aseg√∫rate de que la aplicaci√≥n de Ollama est√© en ejecuci√≥n en segundo plano.

    Descarga el Modelo de Embeddings: Abre tu terminal y ejecuta el siguiente comando para descargar el modelo que usaremos para la memoria sem√°ntica:

    ollama pull snowflake-arctic-embed:335m

5. Configurar las Claves de API

El proyecto necesita claves de API para funcionar.

    Crea el archivo .env: Renombra el archivo .env.example a .env.

    mv .env.example .env

    A√±ade tus claves: Abre el archivo .env con un editor de texto y pega tus claves de API:

        GROQ_API_KEY: Obligatoria. Cons√≠guela registr√°ndote en GroqCloud.

        STABILITY_API_KEY: Opcional. Necesaria solo si quieres generar portadas. Cons√≠guela registr√°ndote en Stability AI Platform.

üöÄ C√≥mo Usar la Aplicaci√≥n

Una vez que todo est√© instalado y configurado, ¬°lanzar la aplicaci√≥n es muy f√°cil!

    Aseg√∫rate de que tu entorno virtual est√© activado y que Ollama est√© en ejecuci√≥n.

    Desde la ra√≠z del proyecto, ejecuta el siguiente comando:

    python app.py

